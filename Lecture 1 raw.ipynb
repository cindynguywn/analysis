{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c49faf5-81ac-4954-959f-05d474947d88",
   "metadata": {},
   "source": [
    "# **Image Fundamentals**\n",
    "### By Cindy Nguyen and Claudia Alonzo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9763170-4af8-438d-a503-fca602e4321b",
   "metadata": {},
   "source": [
    "## **1. Overview and Learning Objectives**\n",
    "\n",
    "In this notebook, we will continue our discussion on the fundamentals of image representation and manipulation in Python.\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "1. Understand how spatial and Intensity Resolution play a role in image processing\n",
    "2. Learn methods to resize, rescale and sample images using interpolation\n",
    "3. Understand the relationship between pixels with an emphasis on boundaries and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcc7a1-92e0-4690-81d1-56408d142df0",
   "metadata": {},
   "source": [
    "## **2. Spatial and Intensity Resolution** \n",
    "\n",
    "Let's start with a recap on the difference between spatial and intensity resolution. \n",
    "\n",
    "**Spatial resolution** is a measure of the smallest discernable detail in an image and is quanitatively measured using line pairs per unit distance or dots (pixels) per unit distance.\n",
    "\n",
    "**Intensity resolution** on the other hand refers to the smallest discernable changed in intensity level. \n",
    "\n",
    "What happens when we reduce the spatial resolution in an image? \n",
    "\n",
    "Inherently lower resolution images are smaller than the original, meaning there are less pixel values.\n",
    "To see this concept in play, we will subsample our original \"cells.tif\" image to take every 2nd pixel - then we will zoom it to make it the same size as the original image.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee96cc-6dff-43f0-95d3-a8c6302272c7",
   "metadata": {},
   "source": [
    "As always, we start by importing the libraries that we will be using such as numpy, matplotlib and skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b70aab-eef2-4096-bed8-e75068053555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import skimage.filters as filters\n",
    "from skimage.segmentation.boundaries import find_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbfd064-75cd-4884-988f-b777c50f2d16",
   "metadata": {},
   "source": [
    "Let's import our image \"cells.tif\" and plot it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecd74d-a516-4428-b3e1-9cea7c6d67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e7e74-4cb4-4809-82db-064acf1c8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['classic', 'grayscale', 'bmh'])\n",
    "plt.grid(False)\n",
    "\n",
    "plt.imshow(cells, cmap='Greys_r')  # set color map to greyscale with dim low pixel values and bright higher ones.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c182e7-1ae5-4b40-87bc-3c1f37a73df8",
   "metadata": {},
   "source": [
    "Let's now sample our image by taking every other pixel value - this will reduce our image by half. \n",
    "\n",
    "Remeber from last class, the upper left corner starts from coordinates (0,0).\n",
    "\n",
    "First, start by checking the size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c424920-dbfc-4799-a0f4-0bcf79da6da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5dc7d49-969f-4176-beb9-b7169d2f9116",
   "metadata": {},
   "source": [
    "We can now sample our image and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a5264-70a3-4194-b8d5-8f29fc5c935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all rows with a step of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0742c4-9228-4566-be0b-aaeb6005d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cells_subsampled, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba5873-bb7e-4164-a239-e9ed55a5daf2",
   "metadata": {},
   "source": [
    "Let's check the size/shape to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1748b-3d8e-436f-b0e9-a43a5c856105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "073b0639-0331-468c-bf1f-fcdefc381951",
   "metadata": {},
   "source": [
    "Let's resize the cropped image so that it's the same size as the original image. By doing this we are zooming the image back to the original size so that we can compare them. \n",
    "We are going to resize the image with the resize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ff5ca-2178-4621-904b-c35e125dffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check parameters of resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacd881-e451-4020-818a-042bfbe646b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute resize\n",
    "cells_resized = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fbae2-b337-4292-b5e8-e891626dc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cells_resized,cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b7d1b-9072-4324-96b8-6d0462e36bc9",
   "metadata": {},
   "source": [
    "Check the shape of the resized image to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbab2c-c034-4b65-8a99-be10e4958100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec41e65c-9bf6-4e3e-961c-81b929475404",
   "metadata": {},
   "source": [
    "Let's compare the original, sampled and resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c6696-16b8-4616-945a-ea2f3a965a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "axes[0].axis('off')\n",
    "axes[0].imshow(cells,cmap='Greys_r')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[1].axis('off')\n",
    "axes[1].imshow(cells_subsampled,cmap='Greys_r')\n",
    "axes[1].set_title('Sampled')\n",
    "axes[2].axis('off')\n",
    "axes[2].imshow(cells_resized,cmap='Greys_r')\n",
    "axes[2].set_title('resized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec7a30-95eb-4cfb-b32e-44b1524b81f7",
   "metadata": {},
   "source": [
    "**What are your observations?**\n",
    "\n",
    "By looking at the original and sampled image, we can see that the the sampled has much less detail and one can say that it has less resolution than the original image. \n",
    "What did the resize function do? How does it work?\n",
    "In the resized image, we can see that the figure did not fully restore back to the original image. \n",
    "\n",
    "The resize function uses interpolation technique to resize the image to the desired image shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196ea02-d592-451a-addd-0d028c278c28",
   "metadata": {},
   "source": [
    "## **3. Interpolation**\n",
    "\n",
    "There are three interpolation methods that we will be exploring\n",
    "\n",
    "**1. Nearest Neighbour Interpolation**\n",
    "\n",
    "Assigns to each new location the intensity of its nearest neighbor in the original\n",
    "image. \n",
    "\n",
    "**2. Bilinear Interpolation**\n",
    "\n",
    "We use the four nearest neighbors to estimate the intensity at a given location\n",
    "\n",
    "**3. Bicubic Interpolation**\n",
    "\n",
    "We use the sixteen nearest neighbors of a point to estimate the intensity at a given location\n",
    "\n",
    "**Note:**\n",
    "\n",
    "The default interpolation method for the resize function is bilinear interpolation if the image type is not bool. \n",
    "We can set the interpolation method with the order parameter\n",
    "\n",
    "order 0 = NNI\n",
    "\n",
    "order 1 = Bilinear\n",
    "\n",
    "order 3 = Bicubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1460b-a0ae-4840-809f-b23508c9499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize using NNI\n",
    "resized_NNI = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e7fae-cc9b-47f1-bc86-a834f17dc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize using bicubic\n",
    "resized_bicubic = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeacbdb5-09e6-4db4-b9b7-52a2161722be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "axes[0].axis('off')\n",
    "axes[0].imshow(resized_NNI,cmap='Greys_r')\n",
    "axes[0].set_title('NNI')\n",
    "axes[1].axis('off')\n",
    "axes[1].imshow(cells_resized,cmap='Greys_r')\n",
    "axes[1].set_title('Bilinear')\n",
    "axes[2].axis('off')\n",
    "axes[2].imshow(resized_bicubic,cmap='Greys_r')\n",
    "axes[2].set_title('Bicubic')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab4a3a-bd1a-4595-8f4d-e29a61a3e8a4",
   "metadata": {},
   "source": [
    "**What is the difference we see between NNI, Bilinear and Bicubic?**\n",
    "\n",
    "**NNI** approach is simple but it has the tendency to produce undesirable artifacts, such as severe distortion of straight edges.\n",
    "**Bilinear interpolation** gives much better results than nearest neighbor interpolation, with a modest increase in computational burden\n",
    "**Bicubic interpolation** does a better job of preserving fine detail than its bilinear counterpart. Bicubic interpolation is the standard used in commercial image editing programs, such as Adobe Photoshop and Corel Photopaint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3df4e-9351-42d3-8242-041d50e3c774",
   "metadata": {},
   "source": [
    "**Rescale**\n",
    "\n",
    "There is one other functions that we're also going to introduce to you, the **rescale function**. The rescale function works through receiving a scaling factor to increase/decrease image. This function has the capability to change interpolation method based on our needs similar to the resize function. \n",
    "\n",
    "From cells_subsampled, let's rescale our image by **2 times** to get back to the original image size \n",
    "\n",
    "**Recall:**\n",
    "\n",
    "order 0 = NNI\n",
    "\n",
    "order 1 = Bilinear\n",
    "\n",
    "order 3 = Bicubic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee6ab4-722c-44bb-817c-f2e832a25eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore rescale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee225a98-fd00-4993-890a-32939866bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rescale with a factor of 2 using NNI\n",
    "rescaled_NNI = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f9267-b800-44df-828d-7ea33635fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rescale with a factor of 2 using bilinear interpolation\n",
    "rescaled_bilinear ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51b345-49ce-4b59-adc1-52ceedc4c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rescale with a factor of 2 using bicubic interpolation\n",
    "rescaled_bicubic = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42748208-4b37-47d4-9251-3dad501d2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "axes[0].axis('off')\n",
    "axes[0].imshow(rescaled_NNI,cmap='Greys_r')\n",
    "axes[0].set_title('NNI')\n",
    "axes[1].axis('off')\n",
    "axes[1].imshow(rescaled_bilinear,cmap='Greys_r')\n",
    "axes[1].set_title('Bilinear')\n",
    "axes[2].axis('off')\n",
    "axes[2].imshow(rescaled_bicubic,cmap='Greys_r')\n",
    "axes[2].set_title('Bicubic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2149a-0af3-4f40-a419-88070e5825c2",
   "metadata": {},
   "source": [
    "**When would you use the rescale function vs resize function?**\n",
    "\n",
    "They both do the same operation however:\n",
    "\n",
    "Rescale operation resizes an image by a given scaling factor. The scaling factor can either be a single floating point value, or multiple values - one along each axis.\n",
    "\n",
    "Resize serves the same purpose, but allows to specify an output image shape instead of a scaling factor.\n",
    "\n",
    "**Note that when down-sampling an image, resize and rescale should perform Gaussian smoothing to avoid aliasing artifacts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6c3a3-9532-44c9-8cfa-0313fa4c0320",
   "metadata": {},
   "source": [
    "Let's take a look at down-sampling. Try downsampling \"cells.tif\" by 0.5 (i.e rescale by 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31999b27-1999-4100-baf2-dd114c7c8156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first explore the anit-aliasing parameter in the rescale function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b80ef-e20e-4bb9-a0b2-0e54ce5b3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the original cell image by 0.5 with the anti-aliasing feature turned off\n",
    "down_sampled_cells = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1041d6-9ced-4355-8800-d5a6876ae4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(down_sampled_cells,cmap='Greys_r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290cafd-5184-4818-a72c-f2246e8c3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the original cell image by 0.5 with the anti-aliasing feature turned off\n",
    "down_sampled_cells_aa = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046358f-aadd-435b-8ed7-23fd4750a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(down_sampled_cells_aa,cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf767e-7b3c-4ca7-9d11-2975db7457bd",
   "metadata": {},
   "source": [
    "In the case where we enabled the anti-aliasing feature, the image appears sharper and we can more clearly see more contrast between the intensity levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36283189-80e1-4b8f-9044-32aad6e8f79c",
   "metadata": {},
   "source": [
    "## **4. Edges and Boundaries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5f09e-a51c-43a2-aa36-3fb26adc89a9",
   "metadata": {},
   "source": [
    "### Edges\n",
    "\n",
    "As you can see from interpolation, the relationship between pixels is important to distinguish in order to better understand what is happening in our image. We will be exploring how these three important pixel relationships contribute to improving our abilities to analyze micropscopy images:\n",
    "\n",
    "1. the foreground\n",
    "2. the background\n",
    "and \n",
    "3. edges \n",
    "\n",
    "For this section, edges are defined as intensity discontinuities at where pixels create sharp changes in the brightness of the image (i.e. intensity value). You can think of them as the defined boundary line that separates dark sections of an image with bright sections of an image. These changes are considered significant 'local' changes in the image.\n",
    "\n",
    "Let's start with loading our cells file that we just saw and see what the edges would look like here.\n",
    "We will further explore the various methods on how to read edges later on with subsequent lectures  but for now, we will use canny to demonstrate the concept of edges. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2919ec31-eba6-4ebf-91b8-f74ef07b3b14",
   "metadata": {},
   "source": [
    "We will now load in our image and denoise the image to better control artifacts/noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297436d-9bae-4648-8633-fd67205ef677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "cell = \n",
    "cell_denoised = \n",
    "                \n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax0.imshow(cell_denoised, cmap=plt.cm.gray)\n",
    "ax1.imshow(cell, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc29574-4573-41a4-9223-21d31a48ecfc",
   "metadata": {},
   "source": [
    "Next, we will use the edge detector to find the edges in our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0933fb5-e1dc-425f-a5b0-11b95275df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "edges = \n",
    "\n",
    "f, (ax2, ax3) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax2.imshow(edges)\n",
    "ax3.imshow(cell_denoised, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38941075-4a72-46a4-8fd8-264f47cf2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.canny?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434c200-cdb7-497c-bca7-dd3d242d9071",
   "metadata": {},
   "source": [
    "##### As you can see, the green lines are the edge pixels that mark the bright and dark differences in the image.\n",
    "\n",
    "Play around with other parameters until you reached a point where the edges are best defined. See how it'll look\n",
    "1. with the original cell\n",
    "2. with cell + a different sigma value\n",
    "3. with cell_denoised \n",
    "\n",
    "Do you notice any differences in the pictures when you change sigma values? What difference do you see? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cffa76-286c-4f7d-a9f4-643b095f9068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a4368-0209-445d-85c4-fcc1788e352e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a1432-d8fc-48f6-a80e-fabfb56b27a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b3a202-b000-4467-924c-a7fd61dae49f",
   "metadata": {},
   "source": [
    "### Boundaries \n",
    "\n",
    "Boundaries, unlike edges, are defined as a 'global' concept. Boundaries are the closed paths that are found around and within the entire image instead of being defined on specific local changes. For this lesson, we will define boundaries as closed paths around an image. We will briefly explore how to identify the contours in an image and the signficance of them.\n",
    "\n",
    "Let us import all the necessary programs for this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a325d3-944d-4bce-925d-fe91b391a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure, color\n",
    "from skimage.filters import threshold_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c600af-81fa-44a4-8863-54710c17543b",
   "metadata": {},
   "source": [
    "In order to create contours, Scikit-image requires us to use a binary image to draw out defined boundaries. We will use the denoised image to better smooth out the image in order to avoid unnecessary boundaries being formed using the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d62d85-e9b9-42f0-ba48-b54b7ed8f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate binary image\n",
    "img=\n",
    "thresh = \n",
    "binary = img > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33a7aa-357e-4f5c-ba0b-e811e93a7f2d",
   "metadata": {},
   "source": [
    "Now, we have to detect the contours using this binary image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296901b-b54b-4770-a31d-331c815fff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5bb9b5-e060-4239-9ff9-fb6ac335cd60",
   "metadata": {},
   "source": [
    "Now let's plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b1114-a917-4534-bc70-00a906c07e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(8,8))\n",
    "ax0, ax1= axes.ravel()\n",
    "ax0.imshow(img,plt.cm.gray)\n",
    "ax0.set_title('original image')\n",
    " \n",
    "rows,cols=img.shape\n",
    "ax1.axis([0,rows,cols,0])\n",
    "for n, contour in enumerate(contours):\n",
    "    ax1.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "ax1.axis('image')\n",
    "ax1.set_title('contours');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20109f07-bd60-4778-bbfe-3867c56ab4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure.find_contours?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94d5a2-e589-4bd8-9fea-6fe83f7eea93",
   "metadata": {},
   "source": [
    "It looks really good! \n",
    "\n",
    "Now try this with \n",
    "1) the regular cell image\n",
    "2) the regular cell image and with different threshold value (both lower and higher)\n",
    "3) the denoised cell image with a different threshold value (both lower and higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4557cb-04e2-4854-acfb-fff76a535c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7d490-a3ea-4c6a-b821-89f3eca09090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d48740-0d9a-4f20-b804-3974a7a64606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "419dbf5c-97d5-44f8-99a0-2e96b01a4e37",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "1. Let's compare the edges and boundaries. Try to find a way to show the edge detection alongside with boundaries. Note all the differences you see when comparing the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8a62a-b608-4493-942b-4f952052a5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e2ea03-5860-4f28-861d-7d04e68c047c",
   "metadata": {},
   "source": [
    "2. Why do you think finding these boundaries and edges are important? What do you think this could be applied to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5234d-ef74-460d-a7ed-e30b08f28478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
